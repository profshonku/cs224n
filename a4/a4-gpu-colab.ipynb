{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPytqD2xo22dDcxWoU3Hp9n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsoum/cs224n/blob/main/a4/a4-gpu-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P03JYoMT0bG5",
        "outputId": "064d0800-b82c-4371-f8c6-b8e9ae889b74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cs224n'...\n",
            "remote: Enumerating objects: 263, done.\u001b[K\n",
            "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 263 (delta 69), reused 148 (delta 61), pack-reused 100\u001b[K\n",
            "Receiving objects: 100% (263/263), 74.13 MiB | 22.77 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dsoum/cs224n.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/cs224n/a4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BFwho_r0wgG",
        "outputId": "0f2b615d-aa9f-4fc1-dc93-ae795ba5483f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cs224n/a4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install docopt sentencepiece\n",
        "!pip install -r gpu_requirements.txt"
      ],
      "metadata": {
        "id": "VV9pm7_p1Yp4",
        "outputId": "47af2311-a013-4618-a60d-1e57441d47a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from -r gpu_requirements.txt (line 1)) (3.7)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tqdm==4.29.1\n",
            "  Downloading tqdm-4.29.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m872.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from -r gpu_requirements.txt (line 6)) (1.13.1+cu116)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->-r gpu_requirements.txt (line 1)) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->-r gpu_requirements.txt (line 1)) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->-r gpu_requirements.txt (line 1)) (1.1.1)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from sacrebleu->-r gpu_requirements.txt (line 5)) (4.9.2)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from sacrebleu->-r gpu_requirements.txt (line 5)) (1.22.4)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.9/dist-packages (from sacrebleu->-r gpu_requirements.txt (line 5)) (0.8.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->-r gpu_requirements.txt (line 6)) (4.5.0)\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13721 sha256=bb973da08cb73a1d9ab1a0d819ec90aaea83b5afa535c3107db84b6d60857f69\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
            "Successfully built docopt\n",
            "Installing collected packages: sentencepiece, docopt, tqdm, portalocker, colorama, sacrebleu\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.4.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.29.1 which is incompatible.\n",
            "prophet 1.1.2 requires tqdm>=4.36.1, but you have tqdm 4.29.1 which is incompatible.\n",
            "panel 0.14.4 requires tqdm>=4.48.0, but you have tqdm 4.29.1 which is incompatible.\n",
            "pandas-profiling 3.2.0 requires tqdm>=4.48.2, but you have tqdm 4.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 docopt-0.6.2 portalocker-2.7.0 sacrebleu-2.3.1 sentencepiece-0.1.97 tqdm-4.29.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sh run.sh vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GI-TUsF1NtI",
        "outputId": "b7857f7a-a7cf-4a53-812e-d41441437979"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "read in source sentences: ./chr_en_data/train.chr\n",
            "read in target sentences: ./chr_en_data/train.en\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: ./chr_en_data/train.chr\n",
            "  input_format: \n",
            "  model_prefix: src\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 21000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(350) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(181) LOG(INFO) Loading corpus: ./chr_en_data/train.chr\n",
            "trainer_interface.cc(406) LOG(INFO) Loaded all 16696 sentences\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(427) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(536) LOG(INFO) all chars count=1024249\n",
            "trainer_interface.cc(547) LOG(INFO) Done: 99.95% characters are covered.\n",
            "trainer_interface.cc(557) LOG(INFO) Alphabet size=115\n",
            "trainer_interface.cc(558) LOG(INFO) Final character coverage=0.9995\n",
            "trainer_interface.cc(590) LOG(INFO) Done! preprocessed 16696 sentences.\n",
            "unigram_model_trainer.cc(146) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(150) LOG(INFO) Extracting frequent sub strings...\n",
            "unigram_model_trainer.cc(201) LOG(INFO) Initialized 71584 seed sentencepieces\n",
            "trainer_interface.cc(596) LOG(INFO) Tokenizing input sentences with whitespace: 16696\n",
            "trainer_interface.cc(607) LOG(INFO) Done! 54339\n",
            "unigram_model_trainer.cc(491) LOG(INFO) Using 54339 sentences for EM training\n",
            "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=31853 obj=13.2384 num_tokens=118297 num_tokens/piece=3.71384\n",
            "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=28580 obj=11.3757 num_tokens=118524 num_tokens/piece=4.1471\n",
            "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=23086 obj=11.397 num_tokens=122695 num_tokens/piece=5.31469\n",
            "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=22993 obj=11.3487 num_tokens=122755 num_tokens/piece=5.3388\n",
            "trainer_interface.cc(685) LOG(INFO) Saving model: src.model\n",
            "trainer_interface.cc(697) LOG(INFO) Saving vocabs: src.vocab\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: ./chr_en_data/train.en\n",
            "  input_format: \n",
            "  model_prefix: tgt\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 8000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(350) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(181) LOG(INFO) Loading corpus: ./chr_en_data/train.en\n",
            "trainer_interface.cc(406) LOG(INFO) Loaded all 16696 sentences\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(427) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(536) LOG(INFO) all chars count=1642445\n",
            "trainer_interface.cc(547) LOG(INFO) Done: 99.9521% characters are covered.\n",
            "trainer_interface.cc(557) LOG(INFO) Alphabet size=61\n",
            "trainer_interface.cc(558) LOG(INFO) Final character coverage=0.999521\n",
            "trainer_interface.cc(590) LOG(INFO) Done! preprocessed 16696 sentences.\n",
            "unigram_model_trainer.cc(146) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(150) LOG(INFO) Extracting frequent sub strings...\n",
            "unigram_model_trainer.cc(201) LOG(INFO) Initialized 35820 seed sentencepieces\n",
            "trainer_interface.cc(596) LOG(INFO) Tokenizing input sentences with whitespace: 16696\n",
            "trainer_interface.cc(607) LOG(INFO) Done! 24681\n",
            "unigram_model_trainer.cc(491) LOG(INFO) Using 24681 sentences for EM training\n",
            "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=12950 obj=9.92202 num_tokens=48774 num_tokens/piece=3.76633\n",
            "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=10769 obj=7.89767 num_tokens=48939 num_tokens/piece=4.54443\n",
            "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=8796 obj=7.84656 num_tokens=50602 num_tokens/piece=5.75284\n",
            "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=8788 obj=7.82771 num_tokens=50633 num_tokens/piece=5.76161\n",
            "trainer_interface.cc(685) LOG(INFO) Saving model: tgt.model\n",
            "trainer_interface.cc(697) LOG(INFO) Saving vocabs: tgt.vocab\n",
            "initialize source vocabulary ..\n",
            "initialize target vocabulary ..\n",
            "generated vocabulary, source 21000 words, target 8000 words\n",
            "vocabulary saved to vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install sacrebleu"
      ],
      "metadata": {
        "id": "EIinbSu72dOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!sh run.sh train_local"
      ],
      "metadata": {
        "id": "vSn5k_PX1U-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sh run.sh train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s0_VQkN2Z_l",
        "outputId": "3ac52989-bb96-4600-de9a-96db8f215ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "2023-03-16 14:49:44.296551: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-16 14:49:45.232016: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-16 14:49:45.232130: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-16 14:49:45.232150: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "uniformly initialize parameters [-0.100000, +0.100000]\n",
            "use device: cuda:0\n",
            "begin Maximum Likelihood training\n",
            "epoch 1, iter 10, avg. loss 197.05, avg. ppl 2942.37 cum. examples 320, speed 2190.70 words/sec, time elapsed 3.60 sec\n",
            "epoch 1, iter 20, avg. loss 164.90, avg. ppl 769.43 cum. examples 640, speed 3355.88 words/sec, time elapsed 5.97 sec\n",
            "epoch 1, iter 30, avg. loss 147.22, avg. ppl 539.46 cum. examples 960, speed 3190.57 words/sec, time elapsed 8.32 sec\n",
            "epoch 1, iter 40, avg. loss 146.53, avg. ppl 430.66 cum. examples 1280, speed 3349.21 words/sec, time elapsed 10.63 sec\n",
            "epoch 1, iter 50, avg. loss 147.69, avg. ppl 388.70 cum. examples 1600, speed 3523.79 words/sec, time elapsed 12.87 sec\n",
            "epoch 1, iter 60, avg. loss 153.98, avg. ppl 371.42 cum. examples 1920, speed 3353.53 words/sec, time elapsed 15.36 sec\n",
            "epoch 1, iter 70, avg. loss 147.12, avg. ppl 328.23 cum. examples 2240, speed 3516.81 words/sec, time elapsed 17.67 sec\n",
            "epoch 1, iter 80, avg. loss 139.62, avg. ppl 291.45 cum. examples 2560, speed 3393.37 words/sec, time elapsed 19.99 sec\n",
            "epoch 1, iter 90, avg. loss 129.38, avg. ppl 291.53 cum. examples 2880, speed 3498.16 words/sec, time elapsed 22.07 sec\n",
            "epoch 1, iter 100, avg. loss 139.19, avg. ppl 277.96 cum. examples 3200, speed 3099.61 words/sec, time elapsed 24.63 sec\n",
            "epoch 1, iter 110, avg. loss 130.27, avg. ppl 226.53 cum. examples 3520, speed 3623.50 words/sec, time elapsed 26.75 sec\n",
            "epoch 1, iter 120, avg. loss 125.02, avg. ppl 215.51 cum. examples 3840, speed 3363.41 words/sec, time elapsed 28.96 sec\n",
            "epoch 1, iter 130, avg. loss 133.83, avg. ppl 215.28 cum. examples 4160, speed 3240.21 words/sec, time elapsed 31.42 sec\n",
            "epoch 1, iter 140, avg. loss 126.02, avg. ppl 185.73 cum. examples 4480, speed 3089.92 words/sec, time elapsed 33.92 sec\n",
            "epoch 1, iter 150, avg. loss 130.59, avg. ppl 185.72 cum. examples 4800, speed 3076.57 words/sec, time elapsed 36.52 sec\n",
            "epoch 1, iter 160, avg. loss 134.54, avg. ppl 191.85 cum. examples 5120, speed 3414.54 words/sec, time elapsed 38.92 sec\n",
            "epoch 1, iter 170, avg. loss 121.55, avg. ppl 168.12 cum. examples 5440, speed 3138.62 words/sec, time elapsed 41.34 sec\n",
            "epoch 1, iter 180, avg. loss 129.54, avg. ppl 152.17 cum. examples 5760, speed 3482.06 words/sec, time elapsed 43.71 sec\n",
            "epoch 1, iter 190, avg. loss 117.59, avg. ppl 139.05 cum. examples 6080, speed 3298.13 words/sec, time elapsed 46.02 sec\n",
            "epoch 1, iter 200, avg. loss 117.61, avg. ppl 141.90 cum. examples 6400, speed 3122.54 words/sec, time elapsed 48.45 sec\n",
            "epoch 1, iter 200, cum. loss 138.96, cum. ppl 292.82 cum. examples 6400\n",
            "begin validation ...\n",
            "validation: iter 200, dev. ppl 158.163220\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 1, iter 210, avg. loss 121.49, avg. ppl 136.41 cum. examples 320, speed 967.41 words/sec, time elapsed 56.63 sec\n",
            "epoch 1, iter 220, avg. loss 113.10, avg. ppl 132.51 cum. examples 640, speed 3123.22 words/sec, time elapsed 59.00 sec\n",
            "epoch 1, iter 230, avg. loss 114.62, avg. ppl 119.88 cum. examples 960, speed 3295.00 words/sec, time elapsed 61.33 sec\n",
            "epoch 1, iter 240, avg. loss 122.06, avg. ppl 135.79 cum. examples 1280, speed 3326.08 words/sec, time elapsed 63.72 sec\n",
            "epoch 1, iter 250, avg. loss 120.00, avg. ppl 131.15 cum. examples 1600, speed 3235.87 words/sec, time elapsed 66.15 sec\n",
            "epoch 1, iter 260, avg. loss 117.85, avg. ppl 126.62 cum. examples 1920, speed 3209.70 words/sec, time elapsed 68.58 sec\n",
            "epoch 1, iter 270, avg. loss 115.17, avg. ppl 121.60 cum. examples 2240, speed 3095.61 words/sec, time elapsed 71.06 sec\n",
            "epoch 1, iter 280, avg. loss 117.17, avg. ppl 114.46 cum. examples 2560, speed 3159.36 words/sec, time elapsed 73.56 sec\n",
            "epoch 1, iter 290, avg. loss 115.36, avg. ppl 121.28 cum. examples 2880, speed 3160.23 words/sec, time elapsed 76.00 sec\n",
            "epoch 1, iter 300, avg. loss 115.32, avg. ppl 106.18 cum. examples 3200, speed 3305.94 words/sec, time elapsed 78.39 sec\n",
            "epoch 1, iter 310, avg. loss 111.96, avg. ppl 105.85 cum. examples 3520, speed 3273.89 words/sec, time elapsed 80.74 sec\n",
            "epoch 1, iter 320, avg. loss 112.89, avg. ppl 106.97 cum. examples 3840, speed 3290.10 words/sec, time elapsed 83.09 sec\n",
            "epoch 1, iter 330, avg. loss 118.12, avg. ppl 107.25 cum. examples 4160, speed 3319.31 words/sec, time elapsed 85.52 sec\n",
            "epoch 1, iter 340, avg. loss 113.73, avg. ppl 106.58 cum. examples 4480, speed 2785.03 words/sec, time elapsed 88.32 sec\n",
            "epoch 1, iter 350, avg. loss 116.09, avg. ppl 112.27 cum. examples 4800, speed 3387.46 words/sec, time elapsed 90.64 sec\n",
            "epoch 1, iter 360, avg. loss 112.77, avg. ppl 92.82 cum. examples 5120, speed 3108.78 words/sec, time elapsed 93.21 sec\n",
            "epoch 1, iter 370, avg. loss 112.28, avg. ppl 90.35 cum. examples 5440, speed 3182.06 words/sec, time elapsed 95.71 sec\n",
            "epoch 1, iter 380, avg. loss 110.13, avg. ppl 95.33 cum. examples 5760, speed 3245.92 words/sec, time elapsed 98.10 sec\n",
            "epoch 1, iter 390, avg. loss 102.98, avg. ppl 78.54 cum. examples 6080, speed 3255.53 words/sec, time elapsed 100.42 sec\n",
            "epoch 1, iter 400, avg. loss 106.13, avg. ppl 90.49 cum. examples 6400, speed 3415.39 words/sec, time elapsed 102.62 sec\n",
            "epoch 1, iter 400, cum. loss 114.46, cum. ppl 110.43 cum. examples 6400\n",
            "begin validation ...\n",
            "validation: iter 400, dev. ppl 95.126589\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 1, iter 410, avg. loss 103.27, avg. ppl 84.84 cum. examples 320, speed 922.97 words/sec, time elapsed 110.69 sec\n",
            "epoch 1, iter 420, avg. loss 109.07, avg. ppl 89.99 cum. examples 640, speed 3359.20 words/sec, time elapsed 113.00 sec\n",
            "epoch 1, iter 430, avg. loss 112.79, avg. ppl 89.41 cum. examples 960, speed 3195.33 words/sec, time elapsed 115.51 sec\n",
            "epoch 1, iter 440, avg. loss 111.12, avg. ppl 80.72 cum. examples 1280, speed 3419.29 words/sec, time elapsed 117.88 sec\n",
            "epoch 1, iter 450, avg. loss 109.11, avg. ppl 87.20 cum. examples 1600, speed 3057.51 words/sec, time elapsed 120.43 sec\n",
            "epoch 1, iter 460, avg. loss 105.58, avg. ppl 81.48 cum. examples 1920, speed 2968.78 words/sec, time elapsed 123.02 sec\n",
            "epoch 1, iter 470, avg. loss 103.18, avg. ppl 64.43 cum. examples 2240, speed 3517.82 words/sec, time elapsed 125.27 sec\n",
            "epoch 1, iter 480, avg. loss 105.19, avg. ppl 66.90 cum. examples 2560, speed 3301.97 words/sec, time elapsed 127.70 sec\n",
            "epoch 1, iter 490, avg. loss 106.86, avg. ppl 77.81 cum. examples 2880, speed 3112.98 words/sec, time elapsed 130.22 sec\n",
            "epoch 1, iter 500, avg. loss 104.70, avg. ppl 74.70 cum. examples 3200, speed 2980.48 words/sec, time elapsed 132.83 sec\n",
            "epoch 1, iter 510, avg. loss 102.53, avg. ppl 77.64 cum. examples 3520, speed 2709.75 words/sec, time elapsed 135.61 sec\n",
            "epoch 1, iter 520, avg. loss 109.29, avg. ppl 79.48 cum. examples 3840, speed 3281.63 words/sec, time elapsed 138.05 sec\n",
            "epoch 2, iter 530, avg. loss 96.51, avg. ppl 54.59 cum. examples 4152, speed 3189.71 words/sec, time elapsed 140.41 sec\n",
            "epoch 2, iter 540, avg. loss 99.08, avg. ppl 55.61 cum. examples 4472, speed 3209.31 words/sec, time elapsed 142.86 sec\n",
            "epoch 2, iter 550, avg. loss 96.40, avg. ppl 51.12 cum. examples 4792, speed 3275.57 words/sec, time elapsed 145.26 sec\n",
            "epoch 2, iter 560, avg. loss 96.83, avg. ppl 52.93 cum. examples 5112, speed 2914.47 words/sec, time elapsed 147.94 sec\n",
            "epoch 2, iter 570, avg. loss 100.42, avg. ppl 47.93 cum. examples 5432, speed 3151.72 words/sec, time elapsed 150.57 sec\n",
            "epoch 2, iter 580, avg. loss 92.86, avg. ppl 47.56 cum. examples 5752, speed 3171.65 words/sec, time elapsed 153.00 sec\n",
            "epoch 2, iter 590, avg. loss 91.44, avg. ppl 48.79 cum. examples 6072, speed 3150.64 words/sec, time elapsed 155.39 sec\n",
            "epoch 2, iter 600, avg. loss 95.05, avg. ppl 50.18 cum. examples 6392, speed 3242.70 words/sec, time elapsed 157.78 sec\n",
            "epoch 2, iter 600, cum. loss 102.57, cum. ppl 66.39 cum. examples 6392\n",
            "begin validation ...\n",
            "validation: iter 600, dev. ppl 70.945012\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 2, iter 610, avg. loss 96.20, avg. ppl 53.10 cum. examples 320, speed 931.26 words/sec, time elapsed 166.11 sec\n",
            "epoch 2, iter 620, avg. loss 95.28, avg. ppl 52.13 cum. examples 640, speed 3207.58 words/sec, time elapsed 168.51 sec\n",
            "epoch 2, iter 630, avg. loss 91.63, avg. ppl 42.27 cum. examples 960, speed 3283.78 words/sec, time elapsed 170.89 sec\n",
            "epoch 2, iter 640, avg. loss 97.46, avg. ppl 49.41 cum. examples 1280, speed 2973.78 words/sec, time elapsed 173.58 sec\n",
            "epoch 2, iter 650, avg. loss 98.21, avg. ppl 49.23 cum. examples 1600, speed 3161.55 words/sec, time elapsed 176.13 sec\n",
            "epoch 2, iter 660, avg. loss 96.94, avg. ppl 48.95 cum. examples 1920, speed 3015.62 words/sec, time elapsed 178.78 sec\n",
            "epoch 2, iter 670, avg. loss 89.88, avg. ppl 43.73 cum. examples 2240, speed 3003.33 words/sec, time elapsed 181.31 sec\n",
            "epoch 2, iter 680, avg. loss 93.24, avg. ppl 48.37 cum. examples 2560, speed 2621.17 words/sec, time elapsed 184.25 sec\n",
            "epoch 2, iter 690, avg. loss 94.00, avg. ppl 45.86 cum. examples 2880, speed 3228.57 words/sec, time elapsed 186.68 sec\n",
            "epoch 2, iter 700, avg. loss 88.25, avg. ppl 43.11 cum. examples 3200, speed 2899.96 words/sec, time elapsed 189.27 sec\n",
            "epoch 2, iter 710, avg. loss 95.78, avg. ppl 42.01 cum. examples 3520, speed 2942.42 words/sec, time elapsed 192.06 sec\n",
            "epoch 2, iter 720, avg. loss 93.12, avg. ppl 46.29 cum. examples 3840, speed 3054.93 words/sec, time elapsed 194.60 sec\n",
            "epoch 2, iter 730, avg. loss 93.62, avg. ppl 46.88 cum. examples 4160, speed 3361.92 words/sec, time elapsed 196.92 sec\n",
            "epoch 2, iter 740, avg. loss 100.92, avg. ppl 46.00 cum. examples 4480, speed 3125.27 words/sec, time elapsed 199.62 sec\n",
            "epoch 2, iter 750, avg. loss 95.37, avg. ppl 43.30 cum. examples 4800, speed 3353.24 words/sec, time elapsed 202.03 sec\n",
            "epoch 2, iter 760, avg. loss 96.31, avg. ppl 49.68 cum. examples 5120, speed 2973.29 words/sec, time elapsed 204.69 sec\n",
            "epoch 2, iter 770, avg. loss 86.73, avg. ppl 45.50 cum. examples 5440, speed 2676.24 words/sec, time elapsed 207.40 sec\n",
            "epoch 2, iter 780, avg. loss 92.62, avg. ppl 41.73 cum. examples 5760, speed 3203.20 words/sec, time elapsed 209.88 sec\n",
            "epoch 2, iter 790, avg. loss 91.89, avg. ppl 42.44 cum. examples 6080, speed 2931.60 words/sec, time elapsed 212.56 sec\n",
            "epoch 2, iter 800, avg. loss 90.46, avg. ppl 45.51 cum. examples 6400, speed 2883.94 words/sec, time elapsed 215.19 sec\n",
            "epoch 2, iter 800, cum. loss 93.90, cum. ppl 46.15 cum. examples 6400\n",
            "begin validation ...\n",
            "validation: iter 800, dev. ppl 57.825054\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 2, iter 810, avg. loss 95.17, avg. ppl 46.17 cum. examples 320, speed 980.14 words/sec, time elapsed 223.30 sec\n",
            "epoch 2, iter 820, avg. loss 86.79, avg. ppl 43.59 cum. examples 640, speed 2911.05 words/sec, time elapsed 225.82 sec\n",
            "epoch 2, iter 830, avg. loss 95.46, avg. ppl 45.05 cum. examples 960, speed 3324.40 words/sec, time elapsed 228.24 sec\n",
            "epoch 2, iter 840, avg. loss 87.99, avg. ppl 43.91 cum. examples 1280, speed 3011.65 words/sec, time elapsed 230.71 sec\n",
            "epoch 2, iter 850, avg. loss 93.17, avg. ppl 38.57 cum. examples 1600, speed 3173.75 words/sec, time elapsed 233.28 sec\n",
            "epoch 2, iter 860, avg. loss 93.83, avg. ppl 45.61 cum. examples 1920, speed 3106.82 words/sec, time elapsed 235.81 sec\n",
            "epoch 2, iter 870, avg. loss 92.91, avg. ppl 42.55 cum. examples 2240, speed 3079.20 words/sec, time elapsed 238.39 sec\n",
            "epoch 2, iter 880, avg. loss 89.79, avg. ppl 41.66 cum. examples 2560, speed 2914.45 words/sec, time elapsed 241.03 sec\n",
            "epoch 2, iter 890, avg. loss 86.93, avg. ppl 42.05 cum. examples 2880, speed 3206.24 words/sec, time elapsed 243.35 sec\n",
            "epoch 2, iter 900, avg. loss 90.30, avg. ppl 40.68 cum. examples 3200, speed 3369.44 words/sec, time elapsed 245.66 sec\n",
            "epoch 2, iter 910, avg. loss 90.09, avg. ppl 41.18 cum. examples 3520, speed 2998.59 words/sec, time elapsed 248.25 sec\n",
            "epoch 2, iter 920, avg. loss 89.37, avg. ppl 38.03 cum. examples 3840, speed 3171.07 words/sec, time elapsed 250.73 sec\n",
            "epoch 2, iter 930, avg. loss 92.34, avg. ppl 37.78 cum. examples 4160, speed 3176.41 words/sec, time elapsed 253.29 sec\n",
            "epoch 2, iter 940, avg. loss 85.70, avg. ppl 37.72 cum. examples 4480, speed 3019.73 words/sec, time elapsed 255.79 sec\n",
            "epoch 2, iter 950, avg. loss 89.69, avg. ppl 41.80 cum. examples 4800, speed 2996.64 words/sec, time elapsed 258.36 sec\n",
            "epoch 2, iter 960, avg. loss 85.65, avg. ppl 39.07 cum. examples 5120, speed 2902.02 words/sec, time elapsed 260.94 sec\n",
            "epoch 2, iter 970, avg. loss 84.30, avg. ppl 36.00 cum. examples 5440, speed 3332.96 words/sec, time elapsed 263.19 sec\n",
            "epoch 2, iter 980, avg. loss 97.14, avg. ppl 44.96 cum. examples 5760, speed 3039.06 words/sec, time elapsed 265.88 sec\n",
            "epoch 2, iter 990, avg. loss 90.25, avg. ppl 36.16 cum. examples 6080, speed 3203.83 words/sec, time elapsed 268.39 sec\n",
            "epoch 2, iter 1000, avg. loss 89.98, avg. ppl 39.73 cum. examples 6400, speed 3106.08 words/sec, time elapsed 270.91 sec\n",
            "epoch 2, iter 1000, cum. loss 90.34, cum. ppl 41.00 cum. examples 6400\n",
            "begin validation ...\n",
            "validation: iter 1000, dev. ppl 49.325574\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 2, iter 1010, avg. loss 89.86, avg. ppl 37.49 cum. examples 320, speed 1003.46 words/sec, time elapsed 278.82 sec\n",
            "epoch 2, iter 1020, avg. loss 84.85, avg. ppl 33.59 cum. examples 640, speed 3305.57 words/sec, time elapsed 281.16 sec\n",
            "epoch 2, iter 1030, avg. loss 86.64, avg. ppl 34.08 cum. examples 960, speed 3173.78 words/sec, time elapsed 283.63 sec\n",
            "epoch 2, iter 1040, avg. loss 87.14, avg. ppl 34.57 cum. examples 1280, speed 3140.80 words/sec, time elapsed 286.14 sec\n",
            "epoch 3, iter 1050, avg. loss 82.09, avg. ppl 30.66 cum. examples 1592, speed 2756.97 words/sec, time elapsed 288.85 sec\n",
            "epoch 3, iter 1060, avg. loss 74.52, avg. ppl 22.60 cum. examples 1912, speed 3119.73 words/sec, time elapsed 291.30 sec\n",
            "epoch 3, iter 1070, avg. loss 74.67, avg. ppl 24.57 cum. examples 2232, speed 2887.35 words/sec, time elapsed 293.89 sec\n",
            "epoch 3, iter 1080, avg. loss 75.05, avg. ppl 22.22 cum. examples 2552, speed 3272.98 words/sec, time elapsed 296.26 sec\n",
            "epoch 3, iter 1090, avg. loss 78.24, avg. ppl 22.94 cum. examples 2872, speed 3043.94 words/sec, time elapsed 298.88 sec\n",
            "epoch 3, iter 1100, avg. loss 77.41, avg. ppl 23.76 cum. examples 3192, speed 3014.98 words/sec, time elapsed 301.48 sec\n",
            "epoch 3, iter 1110, avg. loss 75.64, avg. ppl 22.76 cum. examples 3512, speed 2951.37 words/sec, time elapsed 304.10 sec\n",
            "epoch 3, iter 1120, avg. loss 76.15, avg. ppl 22.38 cum. examples 3832, speed 3097.42 words/sec, time elapsed 306.63 sec\n",
            "epoch 3, iter 1130, avg. loss 79.76, avg. ppl 24.19 cum. examples 4152, speed 2809.47 words/sec, time elapsed 309.48 sec\n",
            "epoch 3, iter 1140, avg. loss 80.33, avg. ppl 24.06 cum. examples 4472, speed 3042.45 words/sec, time elapsed 312.14 sec\n",
            "epoch 3, iter 1150, avg. loss 68.12, avg. ppl 19.65 cum. examples 4792, speed 3101.81 words/sec, time elapsed 314.50 sec\n",
            "epoch 3, iter 1160, avg. loss 79.38, avg. ppl 22.96 cum. examples 5112, speed 3093.87 words/sec, time elapsed 317.12 sec\n",
            "epoch 3, iter 1170, avg. loss 76.18, avg. ppl 22.65 cum. examples 5432, speed 3166.84 words/sec, time elapsed 319.59 sec\n",
            "epoch 3, iter 1180, avg. loss 76.06, avg. ppl 22.24 cum. examples 5752, speed 3257.98 words/sec, time elapsed 321.99 sec\n",
            "epoch 3, iter 1190, avg. loss 75.66, avg. ppl 23.13 cum. examples 6072, speed 3201.34 words/sec, time elapsed 324.40 sec\n",
            "epoch 3, iter 1200, avg. loss 76.33, avg. ppl 22.07 cum. examples 6392, speed 3118.51 words/sec, time elapsed 326.93 sec\n",
            "epoch 3, iter 1200, cum. loss 78.70, cum. ppl 25.19 cum. examples 6392\n",
            "begin validation ...\n",
            "validation: iter 1200, dev. ppl 45.000120\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 3, iter 1210, avg. loss 71.85, avg. ppl 21.20 cum. examples 320, speed 961.07 words/sec, time elapsed 334.77 sec\n",
            "epoch 3, iter 1220, avg. loss 75.49, avg. ppl 21.91 cum. examples 640, speed 3060.20 words/sec, time elapsed 337.32 sec\n",
            "epoch 3, iter 1230, avg. loss 70.43, avg. ppl 19.57 cum. examples 960, speed 3070.88 words/sec, time elapsed 339.79 sec\n",
            "epoch 3, iter 1240, avg. loss 73.44, avg. ppl 20.28 cum. examples 1280, speed 3173.91 words/sec, time elapsed 342.25 sec\n",
            "epoch 3, iter 1250, avg. loss 77.31, avg. ppl 21.89 cum. examples 1600, speed 3310.64 words/sec, time elapsed 344.67 sec\n",
            "epoch 3, iter 1260, avg. loss 73.03, avg. ppl 20.50 cum. examples 1920, speed 3453.40 words/sec, time elapsed 346.92 sec\n",
            "epoch 3, iter 1270, avg. loss 76.07, avg. ppl 23.63 cum. examples 2240, speed 3029.74 words/sec, time elapsed 349.46 sec\n",
            "epoch 3, iter 1280, avg. loss 77.51, avg. ppl 21.74 cum. examples 2560, speed 3317.82 words/sec, time elapsed 351.88 sec\n",
            "epoch 3, iter 1290, avg. loss 77.37, avg. ppl 22.39 cum. examples 2880, speed 3200.03 words/sec, time elapsed 354.37 sec\n",
            "epoch 3, iter 1300, avg. loss 75.54, avg. ppl 20.54 cum. examples 3200, speed 2970.56 words/sec, time elapsed 357.07 sec\n",
            "epoch 3, iter 1310, avg. loss 74.97, avg. ppl 19.82 cum. examples 3520, speed 3176.65 words/sec, time elapsed 359.59 sec\n",
            "epoch 3, iter 1320, avg. loss 75.29, avg. ppl 20.26 cum. examples 3840, speed 3255.88 words/sec, time elapsed 362.05 sec\n",
            "epoch 3, iter 1330, avg. loss 74.16, avg. ppl 22.15 cum. examples 4160, speed 2797.88 words/sec, time elapsed 364.79 sec\n",
            "epoch 3, iter 1340, avg. loss 76.18, avg. ppl 20.83 cum. examples 4480, speed 3177.85 words/sec, time elapsed 367.32 sec\n",
            "epoch 3, iter 1350, avg. loss 76.97, avg. ppl 22.31 cum. examples 4800, speed 2877.42 words/sec, time elapsed 370.08 sec\n",
            "epoch 3, iter 1360, avg. loss 71.63, avg. ppl 20.44 cum. examples 5120, speed 2719.64 words/sec, time elapsed 372.87 sec\n",
            "epoch 3, iter 1370, avg. loss 79.93, avg. ppl 24.98 cum. examples 5440, speed 2910.62 words/sec, time elapsed 375.61 sec\n",
            "epoch 3, iter 1380, avg. loss 72.37, avg. ppl 20.77 cum. examples 5760, speed 3077.90 words/sec, time elapsed 378.09 sec\n",
            "epoch 3, iter 1390, avg. loss 73.49, avg. ppl 22.00 cum. examples 6080, speed 3168.21 words/sec, time elapsed 380.49 sec\n",
            "epoch 3, iter 1400, avg. loss 78.00, avg. ppl 22.85 cum. examples 6400, speed 2989.71 words/sec, time elapsed 383.16 sec\n",
            "epoch 3, iter 1400, cum. loss 75.05, cum. ppl 21.47 cum. examples 6400\n",
            "begin validation ...\n",
            "validation: iter 1400, dev. ppl 41.518228\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 3, iter 1410, avg. loss 72.98, avg. ppl 19.77 cum. examples 320, speed 1009.47 words/sec, time elapsed 390.91 sec\n",
            "epoch 3, iter 1420, avg. loss 73.55, avg. ppl 20.21 cum. examples 640, speed 3193.28 words/sec, time elapsed 393.36 sec\n",
            "epoch 3, iter 1430, avg. loss 71.58, avg. ppl 19.68 cum. examples 960, speed 2941.73 words/sec, time elapsed 395.97 sec\n",
            "epoch 3, iter 1440, avg. loss 70.09, avg. ppl 19.70 cum. examples 1280, speed 3259.83 words/sec, time elapsed 398.28 sec\n",
            "epoch 3, iter 1450, avg. loss 74.18, avg. ppl 21.61 cum. examples 1600, speed 3085.77 words/sec, time elapsed 400.78 sec\n",
            "epoch 3, iter 1460, avg. loss 72.45, avg. ppl 19.86 cum. examples 1920, speed 2951.94 words/sec, time elapsed 403.41 sec\n",
            "epoch 3, iter 1470, avg. loss 74.15, avg. ppl 23.75 cum. examples 2240, speed 3123.58 words/sec, time elapsed 405.81 sec\n",
            "epoch 3, iter 1480, avg. loss 78.24, avg. ppl 22.56 cum. examples 2560, speed 2859.96 words/sec, time elapsed 408.62 sec\n",
            "epoch 3, iter 1490, avg. loss 70.73, avg. ppl 18.14 cum. examples 2880, speed 3314.50 words/sec, time elapsed 410.98 sec\n",
            "epoch 3, iter 1500, avg. loss 75.59, avg. ppl 20.67 cum. examples 3200, speed 3114.48 words/sec, time elapsed 413.54 sec\n",
            "epoch 3, iter 1510, avg. loss 75.18, avg. ppl 21.18 cum. examples 3520, speed 3113.96 words/sec, time elapsed 416.07 sec\n",
            "epoch 3, iter 1520, avg. loss 71.35, avg. ppl 18.93 cum. examples 3840, speed 3120.32 words/sec, time elapsed 418.56 sec\n",
            "epoch 3, iter 1530, avg. loss 72.68, avg. ppl 20.71 cum. examples 4160, speed 3063.35 words/sec, time elapsed 421.06 sec\n",
            "epoch 3, iter 1540, avg. loss 81.35, avg. ppl 22.17 cum. examples 4480, speed 2981.26 words/sec, time elapsed 423.88 sec\n",
            "epoch 3, iter 1550, avg. loss 77.51, avg. ppl 22.29 cum. examples 4800, speed 2698.21 words/sec, time elapsed 426.84 sec\n",
            "epoch 3, iter 1560, avg. loss 72.62, avg. ppl 20.52 cum. examples 5120, speed 3102.94 words/sec, time elapsed 429.32 sec\n",
            "epoch 4, iter 1570, avg. loss 65.58, avg. ppl 17.20 cum. examples 5432, speed 2897.34 words/sec, time elapsed 431.81 sec\n",
            "epoch 4, iter 1580, avg. loss 63.38, avg. ppl 11.57 cum. examples 5752, speed 3000.78 words/sec, time elapsed 434.57 sec\n",
            "epoch 4, iter 1590, avg. loss 62.46, avg. ppl 12.13 cum. examples 6072, speed 2879.93 words/sec, time elapsed 437.35 sec\n",
            "epoch 4, iter 1600, avg. loss 63.23, avg. ppl 12.74 cum. examples 6392, speed 3139.98 words/sec, time elapsed 439.88 sec\n",
            "epoch 4, iter 1600, cum. loss 71.95, cum. ppl 18.89 cum. examples 6392\n",
            "begin validation ...\n",
            "validation: iter 1600, dev. ppl 40.269900\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 4, iter 1610, avg. loss 60.63, avg. ppl 11.80 cum. examples 320, speed 941.04 words/sec, time elapsed 448.23 sec\n",
            "epoch 4, iter 1620, avg. loss 57.88, avg. ppl 12.30 cum. examples 640, speed 3214.21 words/sec, time elapsed 450.53 sec\n",
            "epoch 4, iter 1630, avg. loss 65.71, avg. ppl 13.39 cum. examples 960, speed 2920.98 words/sec, time elapsed 453.30 sec\n",
            "epoch 4, iter 1640, avg. loss 59.38, avg. ppl 11.01 cum. examples 1280, speed 3197.35 words/sec, time elapsed 455.78 sec\n",
            "epoch 4, iter 1650, avg. loss 58.90, avg. ppl 11.20 cum. examples 1600, speed 2966.80 words/sec, time elapsed 458.41 sec\n",
            "epoch 4, iter 1660, avg. loss 63.88, avg. ppl 12.35 cum. examples 1920, speed 3118.79 words/sec, time elapsed 461.02 sec\n",
            "epoch 4, iter 1670, avg. loss 63.71, avg. ppl 12.78 cum. examples 2240, speed 2979.76 words/sec, time elapsed 463.71 sec\n",
            "epoch 4, iter 1680, avg. loss 57.53, avg. ppl 11.09 cum. examples 2560, speed 2988.08 words/sec, time elapsed 466.27 sec\n",
            "epoch 4, iter 1690, avg. loss 60.35, avg. ppl 10.71 cum. examples 2880, speed 3077.37 words/sec, time elapsed 468.91 sec\n",
            "epoch 4, iter 1700, avg. loss 57.40, avg. ppl 11.11 cum. examples 3200, speed 3248.74 words/sec, time elapsed 471.26 sec\n",
            "epoch 4, iter 1710, avg. loss 63.68, avg. ppl 12.31 cum. examples 3520, speed 3141.20 words/sec, time elapsed 473.84 sec\n",
            "epoch 4, iter 1720, avg. loss 60.09, avg. ppl 12.39 cum. examples 3840, speed 3010.49 words/sec, time elapsed 476.38 sec\n",
            "epoch 4, iter 1730, avg. loss 61.03, avg. ppl 12.70 cum. examples 4160, speed 3070.98 words/sec, time elapsed 478.89 sec\n",
            "epoch 4, iter 1740, avg. loss 56.98, avg. ppl 12.12 cum. examples 4480, speed 3170.30 words/sec, time elapsed 481.19 sec\n",
            "epoch 4, iter 1750, avg. loss 60.31, avg. ppl 11.78 cum. examples 4800, speed 3323.93 words/sec, time elapsed 483.54 sec\n",
            "epoch 4, iter 1760, avg. loss 66.58, avg. ppl 13.65 cum. examples 5120, speed 2898.46 words/sec, time elapsed 486.36 sec\n",
            "epoch 4, iter 1770, avg. loss 64.78, avg. ppl 13.62 cum. examples 5440, speed 2973.51 words/sec, time elapsed 489.03 sec\n",
            "epoch 4, iter 1780, avg. loss 59.76, avg. ppl 11.88 cum. examples 5760, speed 3240.37 words/sec, time elapsed 491.41 sec\n",
            "epoch 4, iter 1790, avg. loss 56.71, avg. ppl 11.65 cum. examples 6080, speed 3207.39 words/sec, time elapsed 493.72 sec\n",
            "epoch 4, iter 1800, avg. loss 62.15, avg. ppl 12.17 cum. examples 6400, speed 2683.05 words/sec, time elapsed 496.68 sec\n",
            "epoch 4, iter 1800, cum. loss 60.87, cum. ppl 12.08 cum. examples 6400\n",
            "begin validation ...\n",
            "validation: iter 1800, dev. ppl 40.091085\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 4, iter 1810, avg. loss 60.21, avg. ppl 12.09 cum. examples 320, speed 972.47 words/sec, time elapsed 504.63 sec\n",
            "epoch 4, iter 1820, avg. loss 65.87, avg. ppl 12.93 cum. examples 640, speed 3384.94 words/sec, time elapsed 507.07 sec\n",
            "epoch 4, iter 1830, avg. loss 59.10, avg. ppl 12.23 cum. examples 960, speed 3110.88 words/sec, time elapsed 509.49 sec\n",
            "epoch 4, iter 1840, avg. loss 56.05, avg. ppl 11.51 cum. examples 1280, speed 3352.21 words/sec, time elapsed 511.68 sec\n",
            "epoch 4, iter 1850, avg. loss 60.86, avg. ppl 11.27 cum. examples 1600, speed 3251.83 words/sec, time elapsed 514.16 sec\n",
            "epoch 4, iter 1860, avg. loss 56.53, avg. ppl 10.96 cum. examples 1920, speed 3265.89 words/sec, time elapsed 516.47 sec\n",
            "epoch 4, iter 1870, avg. loss 58.14, avg. ppl 11.26 cum. examples 2240, speed 2848.66 words/sec, time elapsed 519.17 sec\n",
            "epoch 4, iter 1880, avg. loss 60.43, avg. ppl 11.90 cum. examples 2560, speed 3239.77 words/sec, time elapsed 521.58 sec\n",
            "epoch 4, iter 1890, avg. loss 60.08, avg. ppl 11.75 cum. examples 2880, speed 3263.90 words/sec, time elapsed 523.97 sec\n",
            "epoch 4, iter 1900, avg. loss 58.61, avg. ppl 11.83 cum. examples 3200, speed 3061.73 words/sec, time elapsed 526.45 sec\n",
            "epoch 4, iter 1910, avg. loss 59.57, avg. ppl 11.32 cum. examples 3520, speed 3261.99 words/sec, time elapsed 528.86 sec\n",
            "epoch 4, iter 1920, avg. loss 61.35, avg. ppl 11.52 cum. examples 3840, speed 3112.64 words/sec, time elapsed 531.44 sec\n",
            "epoch 4, iter 1930, avg. loss 60.48, avg. ppl 12.56 cum. examples 4160, speed 3061.61 words/sec, time elapsed 533.94 sec\n",
            "epoch 4, iter 1940, avg. loss 58.53, avg. ppl 11.85 cum. examples 4480, speed 3199.88 words/sec, time elapsed 536.30 sec\n",
            "epoch 4, iter 1950, avg. loss 61.47, avg. ppl 12.75 cum. examples 4800, speed 2640.61 words/sec, time elapsed 539.23 sec\n",
            "epoch 4, iter 1960, avg. loss 58.13, avg. ppl 12.20 cum. examples 5120, speed 3072.51 words/sec, time elapsed 541.65 sec\n",
            "epoch 4, iter 1970, avg. loss 57.47, avg. ppl 10.81 cum. examples 5440, speed 3343.49 words/sec, time elapsed 543.96 sec\n",
            "epoch 4, iter 1980, avg. loss 64.26, avg. ppl 13.27 cum. examples 5760, speed 3376.33 words/sec, time elapsed 546.32 sec\n",
            "epoch 4, iter 1990, avg. loss 62.17, avg. ppl 12.82 cum. examples 6080, speed 3261.93 words/sec, time elapsed 548.71 sec\n",
            "epoch 4, iter 2000, avg. loss 55.87, avg. ppl 11.91 cum. examples 6400, speed 3328.90 words/sec, time elapsed 550.88 sec\n",
            "epoch 4, iter 2000, cum. loss 59.76, cum. ppl 11.92 cum. examples 6400\n",
            "begin validation ...\n",
            "validation: iter 2000, dev. ppl 38.035212\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 4, iter 2010, avg. loss 60.64, avg. ppl 12.28 cum. examples 320, speed 936.13 words/sec, time elapsed 559.14 sec\n",
            "epoch 4, iter 2020, avg. loss 62.46, avg. ppl 11.28 cum. examples 640, speed 3304.65 words/sec, time elapsed 561.64 sec\n",
            "epoch 4, iter 2030, avg. loss 63.17, avg. ppl 12.08 cum. examples 960, speed 3118.34 words/sec, time elapsed 564.24 sec\n",
            "epoch 4, iter 2040, avg. loss 59.41, avg. ppl 10.94 cum. examples 1280, speed 2992.67 words/sec, time elapsed 566.89 sec\n",
            "epoch 4, iter 2050, avg. loss 64.44, avg. ppl 12.25 cum. examples 1600, speed 2939.46 words/sec, time elapsed 569.69 sec\n",
            "epoch 4, iter 2060, avg. loss 63.91, avg. ppl 12.76 cum. examples 1920, speed 3187.50 words/sec, time elapsed 572.21 sec\n",
            "epoch 4, iter 2070, avg. loss 60.71, avg. ppl 11.95 cum. examples 2240, speed 3297.41 words/sec, time elapsed 574.59 sec\n",
            "epoch 4, iter 2080, avg. loss 62.30, avg. ppl 12.61 cum. examples 2560, speed 2813.06 words/sec, time elapsed 577.39 sec\n",
            "epoch 5, iter 2090, avg. loss 55.16, avg. ppl 9.94 cum. examples 2872, speed 3130.78 words/sec, time elapsed 579.78 sec\n",
            "epoch 5, iter 2100, avg. loss 44.45, avg. ppl 6.13 cum. examples 3192, speed 3362.97 words/sec, time elapsed 582.11 sec\n",
            "epoch 5, iter 2110, avg. loss 47.27, avg. ppl 7.20 cum. examples 3512, speed 2907.83 words/sec, time elapsed 584.75 sec\n",
            "epoch 5, iter 2120, avg. loss 46.57, avg. ppl 6.79 cum. examples 3832, speed 3316.27 words/sec, time elapsed 587.09 sec\n",
            "epoch 5, iter 2130, avg. loss 47.62, avg. ppl 6.90 cum. examples 4152, speed 3197.99 words/sec, time elapsed 589.56 sec\n",
            "epoch 5, iter 2140, avg. loss 45.44, avg. ppl 6.31 cum. examples 4472, speed 3272.62 words/sec, time elapsed 591.97 sec\n",
            "epoch 5, iter 2150, avg. loss 46.72, avg. ppl 6.97 cum. examples 4792, speed 2892.72 words/sec, time elapsed 594.64 sec\n",
            "epoch 5, iter 2160, avg. loss 48.85, avg. ppl 7.60 cum. examples 5112, speed 3243.15 words/sec, time elapsed 597.01 sec\n",
            "epoch 5, iter 2170, avg. loss 49.21, avg. ppl 7.53 cum. examples 5432, speed 2907.66 words/sec, time elapsed 599.70 sec\n",
            "epoch 5, iter 2180, avg. loss 47.20, avg. ppl 7.13 cum. examples 5752, speed 3111.21 words/sec, time elapsed 602.17 sec\n",
            "epoch 5, iter 2190, avg. loss 49.03, avg. ppl 7.57 cum. examples 6072, speed 2917.82 words/sec, time elapsed 604.82 sec\n",
            "epoch 5, iter 2200, avg. loss 52.52, avg. ppl 7.82 cum. examples 6392, speed 2940.71 words/sec, time elapsed 607.60 sec\n",
            "epoch 5, iter 2200, cum. loss 53.85, cum. ppl 8.91 cum. examples 6392\n",
            "begin validation ...\n",
            "validation: iter 2200, dev. ppl 40.392966\n",
            "hit patience 1\n",
            "hit #1 trial\n",
            "load previously best model and decay learning rate to 0.000250\n",
            "restore parameters of the optimizers\n",
            "epoch 5, iter 2210, avg. loss 50.63, avg. ppl 8.00 cum. examples 320, speed 1418.18 words/sec, time elapsed 613.10 sec\n",
            "epoch 5, iter 2220, avg. loss 50.44, avg. ppl 7.80 cum. examples 640, speed 2963.31 words/sec, time elapsed 615.75 sec\n",
            "epoch 5, iter 2230, avg. loss 48.56, avg. ppl 7.50 cum. examples 960, speed 3087.00 words/sec, time elapsed 618.25 sec\n",
            "epoch 5, iter 2240, avg. loss 46.15, avg. ppl 6.96 cum. examples 1280, speed 2999.12 words/sec, time elapsed 620.78 sec\n",
            "epoch 5, iter 2250, avg. loss 49.93, avg. ppl 7.67 cum. examples 1600, speed 2681.90 words/sec, time elapsed 623.71 sec\n",
            "epoch 5, iter 2260, avg. loss 46.53, avg. ppl 7.34 cum. examples 1920, speed 3262.02 words/sec, time elapsed 626.00 sec\n",
            "epoch 5, iter 2270, avg. loss 46.31, avg. ppl 7.17 cum. examples 2240, speed 3081.48 words/sec, time elapsed 628.44 sec\n",
            "epoch 5, iter 2280, avg. loss 49.10, avg. ppl 7.25 cum. examples 2560, speed 3090.22 words/sec, time elapsed 631.01 sec\n",
            "epoch 5, iter 2290, avg. loss 49.64, avg. ppl 6.86 cum. examples 2880, speed 3180.52 words/sec, time elapsed 633.60 sec\n",
            "epoch 5, iter 2300, avg. loss 46.20, avg. ppl 6.78 cum. examples 3200, speed 3291.12 words/sec, time elapsed 635.95 sec\n",
            "epoch 5, iter 2310, avg. loss 48.02, avg. ppl 7.15 cum. examples 3520, speed 3121.16 words/sec, time elapsed 638.45 sec\n",
            "epoch 5, iter 2320, avg. loss 48.52, avg. ppl 7.30 cum. examples 3840, speed 3112.12 words/sec, time elapsed 640.96 sec\n",
            "epoch 5, iter 2330, avg. loss 50.46, avg. ppl 7.78 cum. examples 4160, speed 2743.04 words/sec, time elapsed 643.83 sec\n",
            "epoch 5, iter 2340, avg. loss 47.01, avg. ppl 7.12 cum. examples 4480, speed 3080.92 words/sec, time elapsed 646.31 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sh run.sh test"
      ],
      "metadata": {
        "id": "A4E7lJH73Cel"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}